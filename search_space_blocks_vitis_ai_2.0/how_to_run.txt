# To quantize certain block of model 
python code/quantization.py --device "cpu" --quant_mode calib --config_file config.json --subset_len 1000 --model_name "b3_48_28_28.pth" --input_shape [48,28,28] 

# To deploy model and get the qunatized model in (onnx, pth, xmodel formta)
sudo /opt/vitis_ai/conda/envs/vitis-ai-pytorch/bin/python ./code/quantization.py --quant_mode test --subset_len 1 --batch_size=1 --config_file config.json --deploy --model_name "b3_48_28_28.pth" --input_shape [48,28,28]


vai_c_xir -x ./quantize_result/MyLargeModel_int.xmodel -a arch.json -o ./compiled -n b3_48_28_28.pth

sudo -E PATH=$PATH:/opt/vitis_ai/conda/envs/vitis-ai-pytorch/bin /opt/vitis_ai/conda/envs/vitis-ai-pytorch/bin/vai_c_xir -x ./quantize_result/MyLargeModel_int.xmodel -a arch.json -o ./compiled -n b3_48_28_28



import torch 
import torch.nn as nn
from blocks import *

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = torch.load('float/b3_48_28_28.pth'))
model = model.to(device)


from pytorch_nndct.apis import Inspector
inspector = Inspector("DPUCZDX8G_ISA1_B4096") 


input = torch.randn(16, 48, 28, 28)
inspector.inspect(model, (input,), device=device, output_dir="inspect", image_format="png")
